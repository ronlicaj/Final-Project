{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98cbab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82752b09",
   "metadata": {},
   "source": [
    "## Bitcoin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bfc5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>44918.183594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>47909.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>47504.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-13</td>\n",
       "      <td>47105.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>48717.289062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date         price\n",
       "0 2021-02-10  44918.183594\n",
       "1 2021-02-11  47909.332031\n",
       "2 2021-02-12  47504.851562\n",
       "3 2021-02-13  47105.515625\n",
       "4 2021-02-14  48717.289062"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('BitCoinData.csv', parse_dates=['Date'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d69f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    214 non-null    datetime64[ns]\n",
      " 1   price   214 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 3.5 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e122ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d715b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc= df_btc.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73616c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>44918.183594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>47909.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-12</th>\n",
       "      <td>47504.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-13</th>\n",
       "      <td>47105.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14</th>\n",
       "      <td>48717.289062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   price\n",
       "Date                    \n",
       "2021-02-10  44918.183594\n",
       "2021-02-11  47909.332031\n",
       "2021-02-12  47504.851562\n",
       "2021-02-13  47105.515625\n",
       "2021-02-14  48717.289062"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3006860",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6207b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e514bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date_dt']=pd.to_datetime(df2.date, errors='coerce')\n",
    "df2['date_dt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.dropna(subset=['date_dt'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date_dt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df2, 'clean_tweets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickle = pd.read_pickle('clean_tweets.pkl')\n",
    "df_pickle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets= df_pickle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the time stamp\n",
    "df_tweets['date_dt']= pd.to_datetime(df_tweets['date_dt'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea32b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets=df_tweets.set_index('date_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the timestamp as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just perform a join and that's it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd33b85",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_tweets, df_btc, how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.price.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ac665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fe9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ff479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.reset_index().rename(columns={'index': 'date_only'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937602e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing only the price\n",
    "def mn_scale(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d25c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['price_norm'] =mn_scale(df_merged.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_merged\n",
    " .groupby('date_only')\n",
    " .agg({'subjectivity': 'mean', 'polarity': 'mean', 'price_norm': 'mean'})\n",
    " #.reset_index()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84081891",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8763357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all the categorical columns \n",
    "[col for col in df.columns if not col in df._get_numeric_data().columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82333ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a new subset -> numerical columns as the new DF\n",
    "numerical = df._get_numeric_data()\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a new subset -> cathegorical columns as the new DF\n",
    "categorical=[i for i in df.columns if df.dtypes[i]=='object']\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf55c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split between the independent variables and the target variable\n",
    "X=numerical.drop('total_claim_amount', axis=1)\n",
    "y=numerical.total_claim_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data and splitting it into train and test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test  = pd.DataFrame(X_test , columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a pipeline for validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b534ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for linear regression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4ba32",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21403068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols = LinearRegression(normalize=True)\n",
    "ols.fit(X_train,y_train)\n",
    "\n",
    "# predictions for our model\n",
    "pred = ols.predict(X_test)\n",
    "\n",
    "# regression evaluation metrics\n",
    "test_pred = ols.predict(X_test)\n",
    "train_pred = ols.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60ca8e",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept\n",
    "print(ols.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(ols.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a2b58",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One common pattern within machine learning is to use linear models\n",
    "#trained on nonlinear functions of the data. This approach maintains\n",
    "#the generally fast performance of linear methods, while allowing them\n",
    "# to fit a much wider range of data.\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_2_d = poly_reg.fit_transform(X_train)\n",
    "X_test_2_d = poly_reg.transform(X_test)\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train_2_d,y_train)\n",
    "\n",
    "test_pred = lin_reg.predict(X_test_2_d)\n",
    "train_pred = lin_reg.predict(X_train_2_d)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b120f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bfcd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc1e87a",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99d256",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''Gradient Descent is a very generic optimization algorithm capable of\n",
    " finding optimal solutions to a wide range of problems. The general\n",
    " idea of Gradient Sescent is to tweak parameters iteratively in order\n",
    " to minimize a cost function. Gradient Descent measures the local gradient\n",
    " of the error function with regards to the parameters vector, and it goes \n",
    " in the direction of descending gradient. Once the gradient is zero, you\n",
    " have reached a minimum.'''\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = sgd_reg.predict(X_test)\n",
    "train_pred = sgd_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d0e75",
   "metadata": {},
   "source": [
    "## Artficial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefba832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(0.00001), loss='mse')\n",
    "\n",
    "r = model.fit(X_train, y_train,\n",
    "              validation_data=(X_test,y_test),\n",
    "              batch_size=1,\n",
    "              epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7740c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1682f",
   "metadata": {},
   "source": [
    "## Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52969193",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.set_index('Model', inplace=True)\n",
    "results_df['R2 Square'].plot(kind='barh', figsize=(12, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
